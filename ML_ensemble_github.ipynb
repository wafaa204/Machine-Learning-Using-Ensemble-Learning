{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load important library  "
      ],
      "metadata": {
        "id": "CvXHWYnjJRGZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TLf7frLq0RxF"
      },
      "outputs": [],
      "source": [
        "#load important lib ...\n",
        "#load_breast_cancer: built-in dataset (features X, labels y)...\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "#train_test_split: splits data into training and test sets...\n",
        "from sklearn.model_selection import train_test_split\n",
        "#StandardScaler: standaries feature to mean 0 and the variance 1 ...\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#main ensemble class for Bagging ,Boosting,Stacking ...\n",
        "from sklearn.ensemble import BaggingClassifier ,StackingClassifier,AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForestClassifier ,GradientBoostingClassifier: extra ensemble models used inside stacking ...\n",
        "from sklearn.ensemble import RandomForestClassifier ,GradientBoostingClassifier\n",
        "#LogisticRegression :use as meta model (final estimator) inside stacking ...\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#DecisionTreeClassifier: (base learner/weak learner) use for Bagging and Boosting ...\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#accuracy_score: to count the accuracy ...\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "aGLA2RUaBJQT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "995IhJ9sJbde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load data ...\n",
        "data=load_breast_cancer()\n",
        "#matrix of features (n_samples,n_features)\n",
        "X=data.data\n",
        "#target labels (0=malignant,1=bengin)\n",
        "Y=data.target"
      ],
      "metadata": {
        "id": "TcjMtgALDVEg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting data into Training and Testing sets"
      ],
      "metadata": {
        "id": "0h0PEeCNJl3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "HXaFPvXZG3T3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "jUbWIqp6KBZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "VGHwNqNmJ9x4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging Classifier"
      ],
      "metadata": {
        "id": "gZiuXFXOKv8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#each base model is decision tree ...\n",
        "#n_estimators: number of trees (more trees = more stable) \"if you incease the number of trees the accuracy will increase but the training will be slow\"...\n",
        "#max_samples: each trees sees 80% from training example (bootstrap example) ...\n",
        "#bootstrap: sampling with replacement ...\n",
        "bag=BaggingClassifier(estimator=DecisionTreeClassifier(),n_estimators=20,max_samples=0.8,bootstrap=True,random_state=42)\n",
        "bag.fit(X_train,Y_train)\n",
        "#bag.predict(X_test): each tree predicts on X_test and baggingclassifier combines them using majority vote ...\n",
        "bag_pred=bag.predict(X_test)\n",
        "bag_acc=accuracy_score(Y_test,bag_pred)\n",
        "print ('The Accuracy For Bagging Classifier: ',bag_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WWPOjudL3b7",
        "outputId": "eba6bcfe-5771-4e2a-9841-69462ac26677"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy For Bagging Classifier:  0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting Classifier"
      ],
      "metadata": {
        "id": "8ZZ3o862PB64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTreeClassifier(max_depth=1): very shallow tree (decision stump) ...\n",
        "#learning_rate: controls the contribution (weights) of each weak new learner(how much each tree will effect in the final decision )if the value near to 1 that mean that will learn quikly and the effect of this tree will be more strong ...\n",
        "boost=AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),n_estimators=50,learning_rate=0.8,random_state=42)\n",
        "boost.fit(X_train,Y_train)\n",
        "boost_pred=boost.predict(X_test)\n",
        "boost_acc=accuracy_score(Y_test,boost_pred)\n",
        "print('The Accuracy For Boosting Classifier: ',bag_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGid7GOKNFRS",
        "outputId": "96fb4ec7-b0bc-4ca1-f75d-2fa1d6541ad7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy For Boosting Classifier:  0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking Classifier"
      ],
      "metadata": {
        "id": "hykFyz6fP9gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models=[('rf',RandomForestClassifier(n_estimators=50,random_state=42)),('gb',GradientBoostingClassifier(random_state=42))]\n",
        "#passthrough: if (True->take Baseline model predictions + raw data) ,(False->Keep things simple and prevent overfitting) ...\n",
        "stack=StackingClassifier(estimators=base_models,final_estimator=LogisticRegression(),passthrough=False)\n",
        "stack.fit(X_train,Y_train)\n",
        "stack_pred=stack.predict(X_test)\n",
        "stack_acc=accuracy_score(Y_test,stack_pred)\n",
        "print('The Accuracy For Stacking Classifier: ',stack_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7RiPtk5P605",
        "outputId": "cfa813fd-d2f5-4de0-bb0f-5f6b7e95288e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy For Stacking Classifier:  0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y55JmQ3JkKLv"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}